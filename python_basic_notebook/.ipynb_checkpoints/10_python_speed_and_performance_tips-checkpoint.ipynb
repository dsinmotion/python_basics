{
 "metadata": {
  "name": "",
  "signature": "sha256:158c3b1789af481c5ce39961b37d7c1831139e84af3cb7102e5acecd7de9008a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Python Performance and Speed Tips\n",
      "\n",
      "###Reference\n",
      "> Python speed wiki: [link](https://wiki.python.org/moin/PythonSpeed#More_Performance_Tips)\n",
      "\n",
      "> Python performance tips: [link](https://wiki.python.org/moin/PythonSpeed/PerformanceTips)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Techniques for Improving Performance and Scalability\n",
      "\n",
      "Here are some coding guidelines for applications that demand peak performance (in terms of memory utilization, speed, or scalability).\n",
      "### Use the best algorithms and fastest tools\n",
      "> - **Membership testing** with **sets** and **dictionaries** is much faster, `O(1)`, than searching sequences, `O(n)`. When testing \"a in b\", b should be a set or dictionary instead of a list or tuple.\n",
      "\n",
      "> - **String concatenation** is best done with **''.join(seq)** which is an `O(n)` process. In contrast, using the '+' or '+=' operators can result in an O(n**2) process because new strings may be built for each intermediate step. The CPython 2.4 interpreter mitigates this issue somewhat; however, ''.join(seq) remains the best practice.\n",
      "\n",
      "> - Many tools come in both **list form and iterator form**. In general, _the **iterator forms are more memory friendly** and more scalable. They are preferred whenever a real list is not required._\n",
      "  - range and xrange\n",
      "  - map and itertools.imap\n",
      "  - list comprehensions and \n",
      "  - generator expressions, dict.items and dict.iteritems\n",
      "  \n",
      "> - Many core building blocks are coded in optimized C. Applications that take advantage of them can make substantial performance gains. The building blocks include all of the builtin datatypes (lists, tuples, sets, and dictionaries) and extension modules like array, itertools, and collections.deque.\n",
      "\n",
      "> - Likewise, the **builtin functions run faster than hand-built equivalents**. For example, map(operator.add, v1, v2) is faster than map(lambda x,y: x+y, v1, v2).\n",
      "\n",
      "> - **Lists** _perform well as either fixed length arrays or variable length stacks_. However, for **queue applications using pop(0) or insert(0,v)), collections.deque() offers superior `O(1)` performance because it avoids the O(n) step of rebuilding a full list for each insertion or deletion**.\n",
      "\n",
      "> - Custom sort ordering is best performed with Py2.4's key= option or with the traditional decorate-sort-undecorate technique. Both approaches call the key function just once per element. In contrast, sort's cmp= option is called many times per element during a sort. For example, sort(key=str.lower) is faster than sort(cmp=lambda a,b: cmp(a.lower(), b.lower())).\n",
      "\n",
      "\n",
      "### Take advantage of interpreter optimizations\n",
      "\n",
      "> - In functions, local variables are accessed more quickly than global variables, builtins, and attribute lookups. So, it is sometimes worth localizing variable access in inner-loops. For example, the code for random.shuffle() localizes access with the line, random=self.random. That saves the shuffling loop from having to repeatedly lookup self.random. Outside of loops, the gain is minimal and rarely worth it.\n",
      "\n",
      "> - The previous recommendation is a generalization of the rule to factor constant expressions out of loops. Likewise, constant folding needs to be done manually. Inside loops, write \"x=3\" instead of \"x=1+2\".\n",
      "\n",
      "> - Function call overhead is large compared to other instructions. Accordingly, it is sometimes worth in-lining code inside time-critical loops.\n",
      "\n",
      "> - List comprehensions run a bit faster than equivalent for-loops (unless you're just going to throw away the result).\n",
      "\n",
      "> - Starting with Py2.3, the interpreter optimizes \"while 1\" to just a single jump. In contrast \"while True\" takes several more steps. While the latter is preferred for clarity, time-critical code should use the first form.\n",
      "\n",
      "> - Multiple assignment is slower than individual assignment. For example \"x,y=a,b\" is slower than \"x=a; y=b\". However, multiple assignment is faster for variable swaps. For example, \"x,y=y,x\" is faster than \"t=x; x=y; y=t\".\n",
      "\n",
      "> - Chained comparisons are faster than using the \"and\" operator.\n",
      "Write \"x < y < z\" instead of \"x < y and y < z\".\n",
      "\n",
      "> - A few fast approaches should be considered hacks and reserved for only the most demanding applications. For example, \"not not x\" is faster than \"bool(x)\".\n",
      "\n",
      "### Performance can dictate overall strategy\n",
      "\n",
      "> - SAX is typically faster and more memory efficient than DOM approaches to XML.\n",
      "\n",
      "> - Use C versions of modules that are used frequently; e.g. cPickle instead of the pickle module, and cStringIO instead of StringIO. Note that on occasion, the C versions are less flexible, so be sure to read the module docs to know what you may be missing.\n",
      "\n",
      "> - Threading can improve the response time in applications that would otherwise waste time waiting for I/O.\n",
      "\n",
      "> - Select can help minimize the overhead for polling multiple sockets.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}